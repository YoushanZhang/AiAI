{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2AXlHhlwIxd","executionInfo":{"status":"ok","timestamp":1710536107738,"user_tz":240,"elapsed":77329,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"667d0033-d9f4-4c73-b5e0-2283cd9a47eb"},"id":"C2AXlHhlwIxd","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"id":"c351b7b9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c351b7b9","executionInfo":{"status":"ok","timestamp":1710537097786,"user_tz":240,"elapsed":542,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"c116478b-eaf3-4d4f-9419-bf8548b8fd7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","import mmap\n","import random\n","import pickle\n","import argparse\n","from transformers import AutoTokenizer\n","import time\n","\n","\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# batch_size = args.batch_size # to use the batch_size cmd arg -> python file_name.py -batch_size 32\n","batch_size = 32\n","block_size = 512\n","max_iters = 1000\n","learning_rate = 2e-4\n","eval_iters = 200\n","n_embd = 512\n","n_head = 4\n","n_layer = 4\n","dropout = 0.2\n","\n","print(device)"]},{"cell_type":"code","source":["data_path = '/content/drive/MyDrive/KatzBot_Data/gpt_cleaned_texts.txt'\n","tokenizer_path = '/content/drive/MyDrive/KatzBot_Data/katzbot_cleaned_text_tokenizer.json'"],"metadata":{"id":"L391B6KQwQi-"},"id":"L391B6KQwQi-","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"516b1cf6","metadata":{"id":"516b1cf6"},"outputs":[],"source":["# # Activate only when you want to build a tokenizer\n","\n","# from tokenizers import Tokenizer\n","# from tokenizers.models import BPE\n","# from tokenizers.trainers import BpeTrainer\n","# from tokenizers.pre_tokenizers import Whitespace\n","\n","\n","# tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n","# tokenizer.pre_tokenizer = Whitespace()\n","\n","# # # Create a BpeTrainer with your desired vocabulary size\n","# vocab_size = 32000  # Adjust the vocabulary size here\n","# trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], vocab_size=vocab_size)\n","\n","# # List of files to train the tokenizer on\n","# files = [data_path]\n","\n","# # Train the tokenizer\n","# tokenizer.train(files, trainer)\n","\n","# # Save the tokenizer\n","# tokenizer.save(tokenizer_path)"]},{"cell_type":"code","source":["from tokenizers import Tokenizer\n","\n","vocab_size = 32000\n","\n","# Load the tokenizer\n","tokenizer = Tokenizer.from_file(tokenizer_path)\n","\n","# Encode and decode functions\n","encode = lambda s: tokenizer.encode(s).ids\n","decode = lambda l: tokenizer.decode(l)\n","\n","# Example usage\n","encoded = encode(\"Youshan Zhang\")\n","decoded = decode(encoded)\n","print(f\"Encoded: {encoded}\\nDecoded: {decoded}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Zub7RjRxqvf","executionInfo":{"status":"ok","timestamp":1710536208373,"user_tz":240,"elapsed":210,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"c33d841f-a1a6-4849-d52e-1246ae28bc5e"},"id":"6Zub7RjRxqvf","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded: [8404, 8106]\n","Decoded: Youshan Zhang\n"]}]},{"cell_type":"code","source":["# Example usage\n","encoded = encode(\"Wang\")\n","decoded = decode(encoded)\n","print(f\"Encoded: {encoded}\\nDecoded: {decoded}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iQHrv5DMxqxz","executionInfo":{"status":"ok","timestamp":1710536211808,"user_tz":240,"elapsed":1,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"5caad62c-17c2-4485-8361-ec7ac427821e"},"id":"iQHrv5DMxqxz","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded: [3675]\n","Decoded: Wang\n"]}]},{"cell_type":"code","source":["# Example usage\n","encoded = encode(\"Manish\")\n","decoded = decode(encoded)\n","print(f\"Encoded: {encoded}\\nDecoded: {decoded}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbXat5OJfu6Q","executionInfo":{"status":"ok","timestamp":1710536214321,"user_tz":240,"elapsed":375,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"61cda599-e976-4c5e-8087-4824019ed70e"},"id":"dbXat5OJfu6Q","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoded: [11099]\n","Decoded: Manish\n"]}]},{"cell_type":"code","execution_count":null,"id":"a2125251","metadata":{"id":"a2125251"},"outputs":[],"source":["def load_dataset_into_memory(filename, split_ratio=0.9):\n","    with open(filename, 'r', encoding='utf-8') as f:\n","        f.seek(0, 2)  # Move the cursor to the end of the file\n","        file_size = f.tell()\n","        f.seek(0)  # Reset cursor to the beginning\n","\n","        train_end = int(file_size * split_ratio)  # Calculate train data end point\n","        train_data = f.read(train_end)  # Read data for training\n","\n","        f.seek(train_end)  # Move cursor to start of validation data\n","        val_data = f.read()  # Read remaining data for validation\n","\n","    return train_data, val_data\n","\n","# Load your dataset and split it into training and validation sets\n","filename = data_path\n","train_data, val_data = load_dataset_into_memory(filename, 0.9)\n","\n","\n","train_encoded = torch.tensor(encode(train_data), dtype=torch.long)\n","val_encoded = torch.tensor(encode(val_data), dtype=torch.long)\n"]},{"cell_type":"code","execution_count":null,"id":"2bb1158a","metadata":{"id":"2bb1158a"},"outputs":[],"source":["def get_batch(split):\n","    # start_time = time.time()\n","    # Select the appropriate dataset based on the split\n","    data = train_encoded if split == 'train' else val_encoded\n","\n","    # Ensure we have enough data to sample from\n","    if data.size(0) > block_size:\n","        ix = torch.randint(0, data.size(0) - block_size, (batch_size,))\n","        x = torch.stack([data[i:i+block_size] for i in ix])\n","        y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n","    else:\n","        raise ValueError(\"Dataset size is too small for the requested block and batch sizes.\")\n","\n","    # Assuming 'device' is defined (e.g., 'cuda' or 'cpu')\n","    x, y = x.to(device), y.to(device)\n","    # print(\"--- %s seconds ---\" % (time.time() - start_time))\n","    return x, y"]},{"cell_type":"code","source":["class Head(nn.Module):\n","    \"\"\" one head of self-attention \"\"\"\n","\n","    def __init__(self, head_size):\n","        super().__init__()\n","        self.key = nn.Linear(n_embd, head_size, bias=False)\n","        self.query = nn.Linear(n_embd, head_size, bias=False)\n","        self.value = nn.Linear(n_embd, head_size, bias=False)\n","        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        # input of size (batch, time-step, channels)\n","        # output of size (batch, time-step, head size)\n","        B,T,C = x.shape\n","        k = self.key(x)   # (B,T,hs)\n","        q = self.query(x) # (B,T,hs)\n","        # compute attention scores (\"affinities\")\n","        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n","        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n","        wei = F.softmax(wei, dim=-1) # (B, T, T)\n","        wei = self.dropout(wei)\n","        # perform the weighted aggregation of the values\n","        v = self.value(x) # (B,T,hs)\n","        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n","        return out\n","\n","# [1, 0, 0]\n","# [1, 0.6, 0]\n","# [1, 0.6, 0.4]\n","class MultiHeadAttention(nn.Module):\n","    \"\"\" multiple heads of self-attention in parallel \"\"\"\n","\n","    def __init__(self, num_heads, head_size):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n","        self.proj = nn.Linear(head_size * num_heads, n_embd)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n","        out = self.dropout(self.proj(out))\n","        return out\n","\n","\n","class FeedFoward(nn.Module):\n","    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n","\n","    def __init__(self, n_embd):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(n_embd, 4 * n_embd),\n","            nn.ReLU(),\n","            nn.Linear(4 * n_embd, n_embd),\n","            nn.Dropout(dropout),\n","        )\n","\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class Block(nn.Module):\n","    \"\"\" Transformer block: communication followed by computation \"\"\"\n","\n","    def __init__(self, n_embd, n_head):\n","        # n_embd: embedding dimension, n_head: the number of heads we'd like\n","        super().__init__()\n","        head_size = n_embd // n_head\n","        self.sa = MultiHeadAttention(n_head, head_size)\n","        self.ffwd = FeedFoward(n_embd)\n","        self.ln1 = nn.LayerNorm(n_embd)\n","        self.ln2 = nn.LayerNorm(n_embd)\n","\n","    def forward(self, x):\n","        y = self.sa(x)\n","        x = self.ln1(x + y)\n","        y = self.ffwd(x)\n","        x = self.ln2(x + y)\n","        return x\n","\n","class GPTLanguageModel(nn.Module):\n","    def __init__(self, vocab_size):\n","        super().__init__()\n","        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n","        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n","        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n","        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n","        self.lm_head = nn.Linear(n_embd, vocab_size)\n","\n","\n","        self.apply(self._init_weights)\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","            if module.bias is not None:\n","                torch.nn.init.zeros_(module.bias)\n","        elif isinstance(module, nn.Embedding):\n","            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n","\n","    def forward(self, index, targets=None):\n","        B, T = index.shape\n","\n","\n","        # idx and targets are both (B,T) tensor of integers\n","        tok_emb = self.token_embedding_table(index) # (B,T,C)\n","        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n","        x = tok_emb + pos_emb # (B,T,C)\n","        x = self.blocks(x) # (B,T,C)\n","        x = self.ln_f(x) # (B,T,C)\n","        logits = self.lm_head(x) # (B,T,vocab_size)\n","\n","        if targets is None:\n","            loss = None\n","        else:\n","            B, T, C = logits.shape\n","            logits = logits.view(B*T, C)\n","            targets = targets.view(B*T)\n","            loss = F.cross_entropy(logits, targets)\n","\n","        return logits, loss\n","\n","    def generate(self, index, max_new_tokens):\n","        # index is (B, T) array of indices in the current context\n","        for _ in range(max_new_tokens):\n","            # crop idx to the last block_size tokens\n","            index_cond = index[:, -block_size:]\n","            # get the predictions\n","            logits, loss = self.forward(index_cond)\n","            # focus only on the last time step\n","            logits = logits[:, -1, :] # becomes (B, C)\n","            # apply softmax to get probabilities\n","            probs = F.softmax(logits, dim=-1) # (B, C)\n","            # sample from the distribution\n","            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n","            # append sampled index to the running sequence\n","            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n","        return index\n","\n","model = GPTLanguageModel(vocab_size)\n","# print('loading model parameters...')\n","# with open('model-01.pkl', 'rb') as f:\n","#     model = pickle.load(f)\n","# print('loaded successfully!')\n","m = model.to(device)"],"metadata":{"id":"pwcPmNIrA0CP"},"id":"pwcPmNIrA0CP","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"7d4a0918","metadata":{"id":"7d4a0918"},"outputs":[],"source":["@torch.no_grad()\n","def estimate_loss():\n","    out = {}\n","    model.eval()\n","    for split in ['train', 'val']:\n","        losses = torch.zeros(eval_iters)\n","        for k in range(eval_iters):\n","\n","            # Ensure we have enough data to sample from\n","            if val_encoded.size(0) > block_size:\n","                ix = torch.randint(0, val_encoded.size(0) - block_size, (batch_size,))\n","                x = torch.stack([val_encoded[i:i+block_size] for i in ix])\n","                y = torch.stack([val_encoded[i+1:i+block_size+1] for i in ix])\n","            else:\n","                raise ValueError(\"Dataset size is too small for the requested block and batch sizes.\")\n","\n","            logits, loss = model(x.to(device), y.to(device))\n","            losses[k] = loss.item()\n","        out[split] = losses.mean()\n","    model.train()\n","    return out\n","\n","\n","\n","    # Assuming 'device' is defined (e.g., 'cuda' or 'cpu')\n","    x, y = x.to(device), y.to(device)"]},{"cell_type":"code","execution_count":null,"id":"c36a1c38","metadata":{"scrolled":false,"id":"c36a1c38","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710537608049,"user_tz":240,"elapsed":494612,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"0208ee37-5ecd-4ad3-c195-6f6bf075c5e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","step: 0, train loss: 10.472, val loss: 10.472\n","1\n","2\n","3\n","4\n","5\n","6\n","7\n","8\n","9\n","10\n","11\n","12\n","13\n","14\n","15\n","16\n","17\n","18\n","19\n","20\n","21\n","22\n","23\n","24\n","25\n","26\n","27\n","28\n","29\n","30\n","31\n","32\n","33\n","34\n","35\n","36\n","37\n","38\n","39\n","40\n","41\n","42\n","43\n","44\n","45\n","46\n","47\n","48\n","49\n","50\n","51\n","52\n","53\n","54\n","55\n","56\n","57\n","58\n","59\n","60\n","61\n","62\n","63\n","64\n","65\n","66\n","67\n","68\n","69\n","70\n","71\n","72\n","73\n","74\n","75\n","76\n","77\n","78\n","79\n","80\n","81\n","82\n","83\n","84\n","85\n","86\n","87\n","88\n","89\n","90\n","91\n","92\n","93\n","94\n","95\n","96\n","97\n","98\n","99\n","100\n","101\n","102\n","103\n","104\n","105\n","106\n","107\n","108\n","109\n","110\n","111\n","112\n","113\n","114\n","115\n","116\n","117\n","118\n","119\n","120\n","121\n","122\n","123\n","124\n","125\n","126\n","127\n","128\n","129\n","130\n","131\n","132\n","133\n","134\n","135\n","136\n","137\n","138\n","139\n","140\n","141\n","142\n","143\n","144\n","145\n","146\n","147\n","148\n","149\n","150\n","151\n","152\n","153\n","154\n","155\n","156\n","157\n","158\n","159\n","160\n","161\n","162\n","163\n","164\n","165\n","166\n","167\n","168\n","169\n","170\n","171\n","172\n","173\n","174\n","175\n","176\n","177\n","178\n","179\n","180\n","181\n","182\n","183\n","184\n","185\n","186\n","187\n","188\n","189\n","190\n","191\n","192\n","193\n","194\n","195\n","196\n","197\n","198\n","199\n","200\n","step: 200, train loss: 4.902, val loss: 4.912\n","201\n","202\n","203\n","204\n","205\n","206\n","207\n","208\n","209\n","210\n","211\n","212\n","213\n","214\n","215\n","216\n","217\n","218\n","219\n","220\n","221\n","222\n","223\n","224\n","225\n","226\n","227\n","228\n","229\n","230\n","231\n","232\n","233\n","234\n","235\n","236\n","237\n","238\n","239\n","240\n","241\n","242\n","243\n","244\n","245\n","246\n","247\n","248\n","249\n","250\n","251\n","252\n","253\n","254\n","255\n","256\n","257\n","258\n","259\n","260\n","261\n","262\n","263\n","264\n","265\n","266\n","267\n","268\n","269\n","270\n","271\n","272\n","273\n","274\n","275\n","276\n","277\n","278\n","279\n","280\n","281\n","282\n","283\n","284\n","285\n","286\n","287\n","288\n","289\n","290\n","291\n","292\n","293\n","294\n","295\n","296\n","297\n","298\n","299\n","300\n","301\n","302\n","303\n","304\n","305\n","306\n","307\n","308\n","309\n","310\n","311\n","312\n","313\n","314\n","315\n","316\n","317\n","318\n","319\n","320\n","321\n","322\n","323\n","324\n","325\n","326\n","327\n","328\n","329\n","330\n","331\n","332\n","333\n","334\n","335\n","336\n","337\n","338\n","339\n","340\n","341\n","342\n","343\n","344\n","345\n","346\n","347\n","348\n","349\n","350\n","351\n","352\n","353\n","354\n","355\n","356\n","357\n","358\n","359\n","360\n","361\n","362\n","363\n","364\n","365\n","366\n","367\n","368\n","369\n","370\n","371\n","372\n","373\n","374\n","375\n","376\n","377\n","378\n","379\n","380\n","381\n","382\n","383\n","384\n","385\n","386\n","387\n","388\n","389\n","390\n","391\n","392\n","393\n","394\n","395\n","396\n","397\n","398\n","399\n","400\n","step: 400, train loss: 4.592, val loss: 4.585\n","401\n","402\n","403\n","404\n","405\n","406\n","407\n","408\n","409\n","410\n","411\n","412\n","413\n","414\n","415\n","416\n","417\n","418\n","419\n","420\n","421\n","422\n","423\n","424\n","425\n","426\n","427\n","428\n","429\n","430\n","431\n","432\n","433\n","434\n","435\n","436\n","437\n","438\n","439\n","440\n","441\n","442\n","443\n","444\n","445\n","446\n","447\n","448\n","449\n","450\n","451\n","452\n","453\n","454\n","455\n","456\n","457\n","458\n","459\n","460\n","461\n","462\n","463\n","464\n","465\n","466\n","467\n","468\n","469\n","470\n","471\n","472\n","473\n","474\n","475\n","476\n","477\n","478\n","479\n","480\n","481\n","482\n","483\n","484\n","485\n","486\n","487\n","488\n","489\n","490\n","491\n","492\n","493\n","494\n","495\n","496\n","497\n","498\n","499\n","500\n","501\n","502\n","503\n","504\n","505\n","506\n","507\n","508\n","509\n","510\n","511\n","512\n","513\n","514\n","515\n","516\n","517\n","518\n","519\n","520\n","521\n","522\n","523\n","524\n","525\n","526\n","527\n","528\n","529\n","530\n","531\n","532\n","533\n","534\n","535\n","536\n","537\n","538\n","539\n","540\n","541\n","542\n","543\n","544\n","545\n","546\n","547\n","548\n","549\n","550\n","551\n","552\n","553\n","554\n","555\n","556\n","557\n","558\n","559\n","560\n","561\n","562\n","563\n","564\n","565\n","566\n","567\n","568\n","569\n","570\n","571\n","572\n","573\n","574\n","575\n","576\n","577\n","578\n","579\n","580\n","581\n","582\n","583\n","584\n","585\n","586\n","587\n","588\n","589\n","590\n","591\n","592\n","593\n","594\n","595\n","596\n","597\n","598\n","599\n","600\n","step: 600, train loss: 4.375, val loss: 4.400\n","601\n","602\n","603\n","604\n","605\n","606\n","607\n","608\n","609\n","610\n","611\n","612\n","613\n","614\n","615\n","616\n","617\n","618\n","619\n","620\n","621\n","622\n","623\n","624\n","625\n","626\n","627\n","628\n","629\n","630\n","631\n","632\n","633\n","634\n","635\n","636\n","637\n","638\n","639\n","640\n","641\n","642\n","643\n","644\n","645\n","646\n","647\n","648\n","649\n","650\n","651\n","652\n","653\n","654\n","655\n","656\n","657\n","658\n","659\n","660\n","661\n","662\n","663\n","664\n","665\n","666\n","667\n","668\n","669\n","670\n","671\n","672\n","673\n","674\n","675\n","676\n","677\n","678\n","679\n","680\n","681\n","682\n","683\n","684\n","685\n","686\n","687\n","688\n","689\n","690\n","691\n","692\n","693\n","694\n","695\n","696\n","697\n","698\n","699\n","700\n","701\n","702\n","703\n","704\n","705\n","706\n","707\n","708\n","709\n","710\n","711\n","712\n","713\n","714\n","715\n","716\n","717\n","718\n","719\n","720\n","721\n","722\n","723\n","724\n","725\n","726\n","727\n","728\n","729\n","730\n","731\n","732\n","733\n","734\n","735\n","736\n","737\n","738\n","739\n","740\n","741\n","742\n","743\n","744\n","745\n","746\n","747\n","748\n","749\n","750\n","751\n","752\n","753\n","754\n","755\n","756\n","757\n","758\n","759\n","760\n","761\n","762\n","763\n","764\n","765\n","766\n","767\n","768\n","769\n","770\n","771\n","772\n","773\n","774\n","775\n","776\n","777\n","778\n","779\n","780\n","781\n","782\n","783\n","784\n","785\n","786\n","787\n","788\n","789\n","790\n","791\n","792\n","793\n","794\n","795\n","796\n","797\n","798\n","799\n","800\n","step: 800, train loss: 4.199, val loss: 4.224\n","801\n","802\n","803\n","804\n","805\n","806\n","807\n","808\n","809\n","810\n","811\n","812\n","813\n","814\n","815\n","816\n","817\n","818\n","819\n","820\n","821\n","822\n","823\n","824\n","825\n","826\n","827\n","828\n","829\n","830\n","831\n","832\n","833\n","834\n","835\n","836\n","837\n","838\n","839\n","840\n","841\n","842\n","843\n","844\n","845\n","846\n","847\n","848\n","849\n","850\n","851\n","852\n","853\n","854\n","855\n","856\n","857\n","858\n","859\n","860\n","861\n","862\n","863\n","864\n","865\n","866\n","867\n","868\n","869\n","870\n","871\n","872\n","873\n","874\n","875\n","876\n","877\n","878\n","879\n","880\n","881\n","882\n","883\n","884\n","885\n","886\n","887\n","888\n","889\n","890\n","891\n","892\n","893\n","894\n","895\n","896\n","897\n","898\n","899\n","900\n","901\n","902\n","903\n","904\n","905\n","906\n","907\n","908\n","909\n","910\n","911\n","912\n","913\n","914\n","915\n","916\n","917\n","918\n","919\n","920\n","921\n","922\n","923\n","924\n","925\n","926\n","927\n","928\n","929\n","930\n","931\n","932\n","933\n","934\n","935\n","936\n","937\n","938\n","939\n","940\n","941\n","942\n","943\n","944\n","945\n","946\n","947\n","948\n","949\n","950\n","951\n","952\n","953\n","954\n","955\n","956\n","957\n","958\n","959\n","960\n","961\n","962\n","963\n","964\n","965\n","966\n","967\n","968\n","969\n","970\n","971\n","972\n","973\n","974\n","975\n","976\n","977\n","978\n","979\n","980\n","981\n","982\n","983\n","984\n","985\n","986\n","987\n","988\n","989\n","990\n","991\n","992\n","993\n","994\n","995\n","996\n","997\n","998\n","999\n","1.9504284858703613\n","Saving model parameters...\n","Model saved successfully!\n"]}],"source":["# create a PyTorch optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","\n","for iter in range(max_iters):\n","    print(iter)\n","    if iter % eval_iters == 0:\n","        losses = estimate_loss()\n","        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n","\n","    # Ensure we have enough data to sample from\n","    if train_encoded.size(0) > block_size:\n","        ix = torch.randint(0, train_encoded.size(0) - block_size, (batch_size,))\n","        x = torch.stack([train_encoded[i:i+block_size] for i in ix])\n","        y = torch.stack([train_encoded[i+1:i+block_size+1] for i in ix])\n","    else:\n","        raise ValueError(\"Dataset size is too small for the requested block and batch sizes.\")\n","\n","    # evaluate the loss\n","    logits, loss = model.forward(x.to(device), y.to(device))\n","    # logits, loss = model.forward(xb, yb)\n","    optimizer.zero_grad(set_to_none=True)\n","    loss.backward()\n","    optimizer.step()\n","\n","print(loss.item())\n","\n","\n","\n","\n","model_save_path = '/content/drive/MyDrive/KatzBot_Data/model/KatzGPT-cleaned_text.pkl'\n","print('Saving model parameters...')\n","with open(model_save_path, 'wb') as f:\n","    pickle.dump(model, f)\n","print('Model saved successfully!')"]},{"cell_type":"code","source":[],"metadata":{"id":"N6mJnwtKKWMl"},"id":"N6mJnwtKKWMl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = '/content/drive/MyDrive/KatzBot_Data/model/KatzGPT-cleaned_text.pkl'\n","tokenizer_path = '/content/drive/MyDrive/KatzBot_Data/katzbot_cleaned_text_tokenizer.json'"],"metadata":{"id":"yP8JyNheLpS4"},"execution_count":null,"outputs":[],"id":"yP8JyNheLpS4"},{"cell_type":"code","source":["from tokenizers import Tokenizer\n","\n","# vocab_size = 50000\n","\n","# Load the tokenizer\n","tokenizer = Tokenizer.from_file(tokenizer_path)\n","\n","# Encode and decode functions\n","encode = lambda s: tokenizer.encode(s).ids\n","decode = lambda l: tokenizer.decode(l)\n","\n","# Load the model\n","# model = GPTLanguageModel(vocab_size)\n","print('loading model parameters...')\n","with open(model_path, 'rb') as f:\n","    model = pickle.load(f)\n","print('loaded successfully!')\n","m = model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710538373410,"user_tz":240,"elapsed":775,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"9d072bbe-2a78-4f4f-b8d3-a5415c262efe","id":"jpEjByvOLpS4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading model parameters...\n","loaded successfully!\n"]}],"id":"jpEjByvOLpS4"},{"cell_type":"code","source":["prompt = 'katz school located in'\n","context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n","generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=20)[0].tolist())\n","print(generated_chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z09zDUhioTb2","executionInfo":{"status":"ok","timestamp":1710538377609,"user_tz":240,"elapsed":769,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"f5d9c0bc-d3a9-463b-ae9e-cd4f3a62b484"},"id":"Z09zDUhioTb2","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["katz school located in the nation , serving a kind in New York University of experience truly fulfilling way for observing nature . In\n"]}]},{"cell_type":"code","source":["prompt = 'Thota Manish Kumar'\n","context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n","generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=20)[0].tolist())\n","print(generated_chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajTlFz63j7mf","executionInfo":{"status":"ok","timestamp":1710538387040,"user_tz":240,"elapsed":231,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"6eae076b-66ad-4337-f235-53e6fc030348"},"id":"ajTlFz63j7mf","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Thota Manish Kumar directly with TransCel of the following articulate during the Katz School report to personally intricate and internet to the safety\n"]}]},{"cell_type":"code","execution_count":null,"id":"b0d4668c","metadata":{"id":"b0d4668c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710538392256,"user_tz":240,"elapsed":629,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"8e4c8641-602a-4c71-d76a-46220342556c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Prof Wang is a Finance at the target of Nephrology . Cli for studying in popular tools for andrew . The Hudson and\n"]}],"source":["prompt = 'Prof Wang is'\n","context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n","generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=20)[0].tolist())\n","print(generated_chars)"]},{"cell_type":"code","source":["prompt = 'Artificial Intelligence program'\n","context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n","generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=20)[0].tolist())\n","print(generated_chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B-xVZC9TMDcy","executionInfo":{"status":"ok","timestamp":1710538395894,"user_tz":240,"elapsed":436,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"2a99f9a5-f3a3-4b50-a132-7da6ad03f245"},"id":"B-xVZC9TMDcy","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Artificial Intelligence program offers students with limited graduate teaching endeavors . The job opportunities for students to fulfilling bioinformatics innovation and information technology\n"]}]},{"cell_type":"code","source":["prompt = 'All applicants to Katz'\n","context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n","generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=20)[0].tolist())\n","print(generated_chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQFapkl4MLJB","executionInfo":{"status":"ok","timestamp":1710538403550,"user_tz":240,"elapsed":822,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"2af1bf4b-3aff-4f63-99df-3fad6ad159f3"},"id":"WQFapkl4MLJB","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["All applicants to Katz includes both nature and facilitating connections between in the skills needed . The most up opportunities can provide applicants\n"]}]},{"cell_type":"code","source":["prompt = 'Katz school is'\n","context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n","generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=20)[0].tolist())\n","print(generated_chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XqxGKl4nMQqI","executionInfo":{"status":"ok","timestamp":1710538407866,"user_tz":240,"elapsed":811,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"65a995a1-6c63-435f-ce29-abfad434f0d2"},"id":"XqxGKl4nMQqI","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Katz school is passionate about the Named after conception or East th Street . Understanding the main introduces students participated in the\n"]}]},{"cell_type":"code","source":["prompt = 'I am Katzbot and I can'\n","context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n","generated_chars = decode(m.generate(context.unsqueeze(0), max_new_tokens=20)[0].tolist())\n","print(generated_chars)"],"metadata":{"id":"WYYi86tsMU5e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710538412193,"user_tz":240,"elapsed":545,"user":{"displayName":"Manish","userId":"15212229913239863034"}},"outputId":"58c559e4-4fda-4329-eca6-2054ccee2bfb"},"id":"WYYi86tsMU5e","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["I am Katz bot and I can gathering data to enhance the dynamic situations . The most influential opportunities can now offers a specialized care and a\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"BWICW0fxkTpe"},"id":"BWICW0fxkTpe","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[{"file_id":"13XQ8PPAmYNOwN01sWsCaYtxUxnpTZgaa","timestamp":1710539363881},{"file_id":"1_lVH_W2HHFNTEVfyPG14Totw4ZOQiq37","timestamp":1710535938498},{"file_id":"1x8DPwtsBU_plEQUksiDIHmTicaE_HA8y","timestamp":1710478876653}],"gpuType":"V100","machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}