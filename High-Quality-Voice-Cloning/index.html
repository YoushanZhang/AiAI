<!DOCTYPE html>
<html lang="en">

<head>
    <title>High Quality Voice Cloning Audio Samples</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <link href="https://fonts.googleapis.com/css?family=Crimson+Text:400,400i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,600" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="index.css">

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

    <div class='section'>
        <h1>High Quality Voice Cloning</h1>
        <p>Audio samples accompanying the paper <i>High Quality Voice Cloning: A Generative Model for Audio in the Frequency Domain</i>.</p>
        <h2>Abstract</h2>
        <p>We incorporate speaker variance information beyond duration (pitch, energy)
to enrich the modelâ€™s understanding of speech variations. These features are used during training and inference, improving the one-tomany mapping problem in TTS. The second approach focuses on
high-fidelity audio generation with long-term coherence. Inspired by AudioLM, we combine advancements in adversarial audio compression, self-supervised learning, and language modeling. Our model
extracts coarse semantic tokens capturing long-term structure from raw audio using a masked language model. Fine-grained acoustic tokens, generated by an EnCodec neural codec similar to SoundStream,
capture audio details. Training a language model on both token types achieves high audio quality and long-term consistency in generated speech.</p>
        <h4>Evaluation Metrics:</h4>
        <p>
        <ul class='toc'>
            <li><a href='https://lightning.ai/docs/torchmetrics/stable/audio/perceptual_evaluation_speech_quality.html' target="_blank">PERCEPTUAL EVALUATION OF SPEECH QUALITY (PESQ)</a></li>
            <li><a href='https://lightning.ai/docs/torchmetrics/stable/audio/signal_distortion_ratio.html' target="_blank">SIGNAL TO DISTORTION RATIO (SDR)</a></li>
            <li><a href='https://lightning.ai/docs/torchmetrics/stable/audio/signal_noise_ratio.html' target="_blank">SIGNAL-TO-NOISE RATIO (SNR)</a></li>
            <li><a href='https://lightning.ai/docs/torchmetrics/stable/audio/short_time_objective_intelligibility.html' target="_blank">SHORT-TIME OBJECTIVE INTELLIGIBILITY (STOI)</a></li>
        </ul>
        </p>

        <!-- <h4>Notes:</h4>
        <p>
        <ul>
            <li>Due to the large number of audio samples on this page, all samples have been compressed (96 kb/s mp3). The uncompressed files are available for download at <a href='https://github.com/audio-samples/audio-samples.github.io'>this repository</a>.</li>
            <li>Audio clips which correspond to ground-truth data are generated by inverting ground-truth spectrograms.</li>
            <li>Samples shown here were selected based on diversity and quality.  Samples used for quantitative experiments in the paper were randomly drawn.</li>
        </ul>
        </p> -->
    </div>

    <hr>
<div class='section table-responsive-sm'>
    <table class="table">
    <h2>Evaluation Metrics  for Different Datasets Split</h2>
    <thead>
        <tr>
            <th>Splits</th>
            <th>PESQ(nb)</th>
            <th>PESQ(wb)</th>
            <th>SDR</th>
            <th>SNR</th>
            <th>STOI</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>Training</td>
            <td>2.780</td>
            <td>1.919</td>
            <td>2.637</td>
            <td>5.179</td>
            <td>0.740</td>
        </tr>
        <tr>
            <td>Validation</td>
            <td>1.972</td>
            <td>1.446</td>
            <td>2.527</td>
            <td>5.137</td>
            <td>0.297</td>
        </tr>
        <tr>
            <td>Testing</td>
            <td>1.855</td>
            <td>1.551</td>
            <td>2.662</td>
            <td>6.329</td>
            <td>0.335</td>
        </tr>
    </tbody>
</table>
</div>

    <hr>

    <div id='section-4' class='section'>
        <h2>Text-to-Speech with Different SOTA Models</h2>
        <p>Samples generated by MelNet trained on the task of single-speaker TTS using professionally recorded audiobook data from the <a href="http://www.cstr.ed.ac.uk/projects/blizzard/">Blizzard 2013</a> dataset.</p>

        <h3>Samples</h3>
        <p>The first audio clip for each text is taken from the dataset and the remaining 3 are samples generated by the model.</p>

        <p class='playlist-title text'>&ldquo;Let's see some examples. So first, right is above the domain adaptation. So in this slide, we will see our,&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/Groundtruth/clip_slide3_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Our model</p><audio preload='metadata' controls><source src='audio/ourmodel/clip_slide3_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Tortoise</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-0/fake-1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Suno-AI/Bark.</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-0/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>

        <p class='playlist-title text'>We have another kind of datasets in the medical field. For example, we have the t one images and we have the flare images if we&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Groundtruth/clip_slide3_0070-0080.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/ourmodel/clip_slide3_0070-0080.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-3/fake-1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-3/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>

        <p class='playlist-title text'>&ldquo;And I will introduce one more of the previous that I developed out of those examples. That's exactly how manifold&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Groundtruth/clip_slide4_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/ourmodel/clip_slide4_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-5/fake-1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-5/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>
        
        <p class='playlist-title text'>&ldquo;Oh, he has been away from New York&mdash;he has been all round the world. He doesn't know many people here, but he's very sociable, and he wants to know every one.&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Groundtruth/clip_slide5_0020-0030.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-6/fake-0.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-6/fake-1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-6/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>

        <p class='playlist-title text'>&ldquo;Different causes of the diseases. If it is one, it means normal. If it is two, it means it's abnormal. So sometimes you&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/Groundtruth/clip_slide7_0020-0030.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='audio/ourmodel/clip_slide7_0020-0030.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-2/fake-1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-2/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>



        <h3>Text-to-Speech with Different Customs Models within Group Members</h3>
        <p>Each unlabelled audio clip is taken from the dataset and the audio clip that directly follows is a sample generated by the model primed with that sequence.</p>

        <p class='playlist-title text'>&ldquo;Especially the amount that data labeling is a big challenge for all existing machine learning. For those, you definitely need to provide feed&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/input/slide29_0100-0110.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Aayush</p><audio preload='metadata' controls><source src='audio/aayush/clip_slide29_0100-0110.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Harsha</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-0/fake-1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Siddanta</p><audio preload='metadata' controls><source src='audio/sid/slide29_0100_0110.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sai</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-0/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>

        <p class='playlist-title text'>Label the input data. So then one features and labels, professor, feature and labels cn, that's yes. Exactly.&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/input/slide30_0060-0070.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Aayush</p><audio preload='metadata' controls><source src='audio/aayush/clip_slide30_0060-0070-aaayush.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Harsha</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-3/fake-1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Siddanta</p><audio preload='metadata' controls><source src='audio/sid/slide30_0060_0070.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sai</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-3/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>

        <p class='playlist-title text'>&ldquo;About two years ago in the two thousand tens. In that, stage, and like, deep learning is rarely and becomes popular. Right?&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/input/slide34_0030-0040.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Aayush</p><audio preload='metadata' controls><source src='audio/aayush/clip_slide34_0030-0040.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Harsha</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-5/fake-1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Siddanta</p><audio preload='metadata' controls><source src='audio/sid/slide34_0030_0040.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sai</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-3/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>
        

        <p class='playlist-title text'>&ldquo;Another trend is about why machine learning models are so popular. Right? Because, there are so many places that we needed to use machine learning&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/input/slide56_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Aayush</p><audio preload='metadata' controls><source src='audio/aayush/clip_slide56_0000-0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Harsha</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-2/fake-1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Siddanta</p><audio preload='metadata' controls><source src='audio/sid/slide56_0000_0010.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sai</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-2/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>
        <p class='playlist-title text'>&ldquo;Your eyes, where is your nose? Where is your mouse? Right? It's funny areas. Right? It's really about personal identification&rdquo;</p>
        <div class='playlist'>
            <div class='labeled-audio'><p class='text'>Ground Truth.</p><audio preload='metadata' controls><source src='audio/input/slide69_0010-0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Aayush</p><audio preload='metadata' controls><source src='audio/aayush/clip_slide69_0010-0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Harsha</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-2/fake-1.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Siddanta</p><audio preload='metadata' controls><source src='audio/sid/slide69_0010_0020.mp3' type='audio/mpeg'></audio></div>
            <div class='labeled-audio'><p class='text'>Sai</p><audio preload='metadata' controls><source src='samples/mp3/blizzard_tts_unbiased/sample-2/fake-2.mp3' type='audio/mpeg'></audio></div>
        </div>
    </div>

    <hr>


    <hr>




</body>
</html>

<script>    
document
    .getElementById('select-speaker')   
    .addEventListener('change', function () {
        'use strict';
        var targets = document.getElementsByClassName("select-speaker")
        for (let i = 0; i < targets.length; i++) {
            name = "samples/mp3/ted_speakers/" + this.value + "/sample-" + i.toString() + ".mp3"
            targets[i].setAttribute("src", name)
            targets[i].parentElement.load()
        }
});
</script>
